{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Offline RAG with Ollama\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates building a **completely offline RAG (Retrieval-Augmented Generation)** system using **Ollama** for local LLMs and embeddings.\n",
    "\n",
    "### üöÄ Benefits of Local RAG:\n",
    "- **100% Offline**: No internet required after setup\n",
    "- **Privacy First**: Your documents never leave your machine\n",
    "- **No API Costs**: Free to run unlimited queries\n",
    "- **Fast**: No network latency\n",
    "- **Full Control**: Customize models and parameters\n",
    "\n",
    "### üìã Architecture:\n",
    "```\n",
    "PDF Documents ‚Üí Load ‚Üí Split ‚Üí Local Embeddings (Ollama) ‚Üí ChromaDB\n",
    "                                                                  ‚Üì\n",
    "User Query ‚Üí Retrieve Similar Chunks ‚Üí Local LLM (Ollama) ‚Üí Answer\n",
    "```\n",
    "\n",
    "### üõ†Ô∏è Components:\n",
    "- **Document Loader**: PyPDFLoader\n",
    "- **Text Splitter**: RecursiveCharacterTextSplitter\n",
    "- **Embeddings**: Ollama with nomic-embed-text (or embeddinggemma)\n",
    "- **Vector Store**: ChromaDB (persistent, local)\n",
    "- **LLM**: Ollama with gemma3:1b\n",
    "- **Chain**: LangChain Expression Language (LCEL)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prerequisites & Installation\n",
    "\n",
    "### Required Software:\n",
    "1. **Ollama**: Download from https://ollama.ai\n",
    "2. **Python 3.9+**: Recommended 3.11 or 3.13\n",
    "\n",
    "### Install Python Packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: langchain-core in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: langchain-community in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: langchain-text-splitters in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain) (1.0.3)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain) (2.12.4)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain-core) (0.4.46)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain-core) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain-core) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain-core) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain-core) (4.15.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.9)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n",
      "Requirement already satisfied: anyio in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (4.11.0)\n",
      "Requirement already satisfied: certifi in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain-community) (1.0.0)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain-community) (2.0.44)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain-community) (3.13.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain-community) (2.12.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain-community) (0.4.3)\n",
      "Requirement already satisfied: numpy>=2.1.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain-community) (2.3.5)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2.3.0)\n",
      "Requirement already satisfied: greenlet>=1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.2.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: langchain-ollama in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: langchain-chroma in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (0.2.6)\n",
      "Requirement already satisfied: chromadb in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (1.3.5)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain-ollama) (1.1.0)\n",
      "Requirement already satisfied: ollama<1.0.0,>=0.6.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain-ollama) (0.6.1)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-ollama) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-ollama) (0.4.46)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-ollama) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-ollama) (2.12.4)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-ollama) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-ollama) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-ollama) (4.15.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (0.25.0)\n",
      "Requirement already satisfied: anyio in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (4.11.0)\n",
      "Requirement already satisfied: certifi in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (1.0.9)\n",
      "Requirement already satisfied: idna in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (0.4.2)\n",
      "Requirement already satisfied: numpy>=2.1.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain-chroma) (2.3.5)\n",
      "Requirement already satisfied: build>=1.0.3 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from chromadb) (1.3.0)\n",
      "Requirement already satisfied: pybase64>=1.4.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from chromadb) (1.4.2)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.38.0)\n",
      "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from chromadb) (5.4.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from chromadb) (1.23.2)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from chromadb) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from chromadb) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from chromadb) (1.38.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from chromadb) (0.22.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from chromadb) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from chromadb) (1.76.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from chromadb) (5.0.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from chromadb) (0.20.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from chromadb) (34.1.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from chromadb) (5.2.0)\n",
      "Requirement already satisfied: rich>=10.11.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from chromadb) (14.2.0)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from chromadb) (4.25.1)\n",
      "Requirement already satisfied: six>=1.5 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (2.3.0)\n",
      "Requirement already satisfied: pyproject_hooks in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: colorama in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Requirement already satisfied: attrs>=22.2.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.29.0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.43.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: requests-oauthlib in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (6.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
      "Requirement already satisfied: coloredlogs in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (25.9.23)\n",
      "Requirement already satisfied: protobuf in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
      "Requirement already satisfied: sympy in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.72.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.38.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.38.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.59b0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.59b0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from tokenizers>=0.13.2->chromadb) (0.36.0)\n",
      "Requirement already satisfied: filelock in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.10.0)\n",
      "Requirement already satisfied: click>=8.0.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from typer>=0.9.0->chromadb) (8.3.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.7.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.2.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
      "Requirement already satisfied: websockets>=10.4 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (1.3.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: pyreadline3 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb) (3.5.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pypdf in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (6.3.0)\n",
      "Requirement already satisfied: tiktoken in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (0.12.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from tiktoken) (2025.11.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from tiktoken) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2025.11.12)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: langchain in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from -r requirements.txt (line 9)) (1.1.0)\n",
      "Requirement already satisfied: langchain-core in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from -r requirements.txt (line 10)) (1.1.0)\n",
      "Requirement already satisfied: langchain-community in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from -r requirements.txt (line 11)) (0.4.1)\n",
      "Requirement already satisfied: langchain-text-splitters in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from -r requirements.txt (line 12)) (1.0.0)\n",
      "Requirement already satisfied: langchain-openai in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from -r requirements.txt (line 18)) (1.1.0)\n",
      "Requirement already satisfied: openai in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from -r requirements.txt (line 19)) (2.8.1)\n",
      "Requirement already satisfied: langchain-google-genai in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from -r requirements.txt (line 22)) (2.0.10)\n",
      "Requirement already satisfied: google-generativeai in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from -r requirements.txt (line 23)) (0.8.5)\n",
      "Requirement already satisfied: langchain-huggingface in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from -r requirements.txt (line 26)) (0.3.1)\n",
      "Requirement already satisfied: sentence-transformers in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from -r requirements.txt (line 27)) (5.1.2)\n",
      "Requirement already satisfied: faiss-cpu==1.12.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from -r requirements.txt (line 36)) (1.12.0)\n",
      "Requirement already satisfied: langchain-chroma in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from -r requirements.txt (line 39)) (0.2.6)\n",
      "Requirement already satisfied: chromadb in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from -r requirements.txt (line 40)) (1.3.5)\n",
      "Requirement already satisfied: pypdf in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from -r requirements.txt (line 54)) (6.3.0)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from -r requirements.txt (line 57)) (4.14.2)\n",
      "Requirement already satisfied: lxml in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from -r requirements.txt (line 58)) (6.0.2)\n",
      "Requirement already satisfied: python-dotenv in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from -r requirements.txt (line 67)) (1.2.1)\n",
      "Requirement already satisfied: tiktoken in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from -r requirements.txt (line 70)) (0.12.0)\n",
      "Requirement already satisfied: jupyter in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from -r requirements.txt (line 73)) (1.1.1)\n",
      "Requirement already satisfied: notebook in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from -r requirements.txt (line 74)) (7.5.0)\n",
      "Requirement already satisfied: ipykernel in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from -r requirements.txt (line 75)) (7.1.0)\n",
      "Requirement already satisfied: numpy in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from -r requirements.txt (line 78)) (2.3.5)\n",
      "Requirement already satisfied: packaging in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from faiss-cpu==1.12.0->-r requirements.txt (line 36)) (25.0)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain->-r requirements.txt (line 9)) (1.0.3)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain->-r requirements.txt (line 9)) (2.12.4)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain-core->-r requirements.txt (line 10)) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain-core->-r requirements.txt (line 10)) (0.4.46)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain-core->-r requirements.txt (line 10)) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain-core->-r requirements.txt (line 10)) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain-core->-r requirements.txt (line 10)) (4.15.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core->-r requirements.txt (line 10)) (3.0.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain->-r requirements.txt (line 9)) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain->-r requirements.txt (line 9)) (1.0.5)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain->-r requirements.txt (line 9)) (0.2.9)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain->-r requirements.txt (line 9)) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain->-r requirements.txt (line 9)) (1.12.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain->-r requirements.txt (line 9)) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain->-r requirements.txt (line 9)) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core->-r requirements.txt (line 10)) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core->-r requirements.txt (line 10)) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core->-r requirements.txt (line 10)) (0.25.0)\n",
      "Requirement already satisfied: anyio in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain->-r requirements.txt (line 9)) (4.11.0)\n",
      "Requirement already satisfied: certifi in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain->-r requirements.txt (line 9)) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain->-r requirements.txt (line 9)) (1.0.9)\n",
      "Requirement already satisfied: idna in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain->-r requirements.txt (line 9)) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain->-r requirements.txt (line 9)) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain->-r requirements.txt (line 9)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain->-r requirements.txt (line 9)) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain->-r requirements.txt (line 9)) (0.4.2)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain-community->-r requirements.txt (line 11)) (1.0.0)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain-community->-r requirements.txt (line 11)) (2.0.44)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain-community->-r requirements.txt (line 11)) (3.13.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain-community->-r requirements.txt (line 11)) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain-community->-r requirements.txt (line 11)) (2.12.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain-community->-r requirements.txt (line 11)) (0.4.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 11)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 11)) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 11)) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 11)) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 11)) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 11)) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 11)) (1.22.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community->-r requirements.txt (line 11)) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community->-r requirements.txt (line 11)) (0.9.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core->-r requirements.txt (line 10)) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core->-r requirements.txt (line 10)) (2.3.0)\n",
      "Requirement already satisfied: greenlet>=1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community->-r requirements.txt (line 11)) (3.2.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community->-r requirements.txt (line 11)) (1.1.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from openai->-r requirements.txt (line 19)) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from openai->-r requirements.txt (line 19)) (0.12.0)\n",
      "Requirement already satisfied: sniffio in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from openai->-r requirements.txt (line 19)) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from openai->-r requirements.txt (line 19)) (4.67.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from tiktoken->-r requirements.txt (line 70)) (2025.11.3)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain-google-genai->-r requirements.txt (line 22)) (1.2.0)\n",
      "INFO: pip is looking at multiple versions of langchain-google-genai to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-google-genai (from -r requirements.txt (line 22))\n",
      "  Downloading langchain_google_genai-3.2.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-ai-generativelanguage<1.0.0,>=0.9.0 (from langchain-google-genai->-r requirements.txt (line 22))\n",
      "  Downloading google_ai_generativelanguage-0.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai->-r requirements.txt (line 22)) (2.28.1)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai->-r requirements.txt (line 22)) (2.43.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai->-r requirements.txt (line 22)) (1.76.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai->-r requirements.txt (line 22)) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai->-r requirements.txt (line 22)) (5.29.5)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai->-r requirements.txt (line 22)) (1.72.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai->-r requirements.txt (line 22)) (1.71.2)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai->-r requirements.txt (line 22)) (6.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai->-r requirements.txt (line 22)) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai->-r requirements.txt (line 22)) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai->-r requirements.txt (line 22)) (0.6.1)\n",
      "INFO: pip is looking at multiple versions of google-generativeai to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting google-generativeai (from -r requirements.txt (line 23))\n",
      "  Downloading google_generativeai-0.8.4-py3-none-any.whl.metadata (4.2 kB)\n",
      "  Downloading google_generativeai-0.8.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "  Downloading google_generativeai-0.8.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "  Downloading google_generativeai-0.8.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "  Downloading google_generativeai-0.8.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "  Downloading google_generativeai-0.7.2-py3-none-any.whl.metadata (4.0 kB)\n",
      "  Downloading google_generativeai-0.7.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "INFO: pip is still looking at multiple versions of google-generativeai to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading google_generativeai-0.7.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "  Downloading google_generativeai-0.6.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "  Downloading google_generativeai-0.5.4-py3-none-any.whl.metadata (3.9 kB)\n",
      "  Downloading google_generativeai-0.5.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "  Downloading google_generativeai-0.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading google_generativeai-0.5.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "  Downloading google_generativeai-0.5.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "  Downloading google_generativeai-0.4.1-py3-none-any.whl.metadata (6.2 kB)\n",
      "  Downloading google_generativeai-0.4.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "  Downloading google_generativeai-0.3.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading google_generativeai-0.3.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading google_generativeai-0.3.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Downloading google_generativeai-0.2.2-py3-none-any.whl.metadata (3.1 kB)\n",
      "  Downloading google_generativeai-0.2.1-py3-none-any.whl.metadata (3.1 kB)\n",
      "  Downloading google_generativeai-0.2.0-py3-none-any.whl.metadata (3.1 kB)\n",
      "  Downloading google_generativeai-0.1.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langchain-google-genai (from -r requirements.txt (line 22))\n",
      "  Downloading langchain_google_genai-3.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading langchain_google_genai-3.0.3-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading langchain_google_genai-3.0.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading langchain_google_genai-3.0.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading langchain_google_genai-3.0.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading langchain_google_genai-2.1.12-py3-none-any.whl.metadata (7.1 kB)\n",
      "INFO: pip is still looking at multiple versions of langchain-google-genai to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading langchain_google_genai-2.1.11-py3-none-any.whl.metadata (6.7 kB)\n",
      "  Downloading langchain_google_genai-2.1.10-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain-google-genai->-r requirements.txt (line 22))\n",
      "  Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting langchain-google-genai (from -r requirements.txt (line 22))\n",
      "  Downloading langchain_google_genai-2.1.9-py3-none-any.whl.metadata (7.2 kB)\n",
      "  Downloading langchain_google_genai-2.1.8-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Downloading langchain_google_genai-2.1.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading langchain_google_genai-2.1.6-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Downloading langchain_google_genai-2.1.5-py3-none-any.whl.metadata (5.2 kB)\n",
      "  Downloading langchain_google_genai-2.1.4-py3-none-any.whl.metadata (5.2 kB)\n",
      "  Downloading langchain_google_genai-2.1.3-py3-none-any.whl.metadata (4.7 kB)\n",
      "  Downloading langchain_google_genai-2.1.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "  Downloading langchain_google_genai-2.1.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "  Downloading langchain_google_genai-2.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "  Downloading langchain_google_genai-2.0.11-py3-none-any.whl.metadata (3.6 kB)\n",
      "  Downloading langchain_google_genai-2.0.9-py3-none-any.whl.metadata (3.6 kB)\n",
      "  Downloading langchain_google_genai-2.0.8-py3-none-any.whl.metadata (3.6 kB)\n",
      "  Downloading langchain_google_genai-2.0.7-py3-none-any.whl.metadata (3.6 kB)\n",
      "  Downloading langchain_google_genai-2.0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "  Downloading langchain_google_genai-2.0.5-py3-none-any.whl.metadata (3.6 kB)\n",
      "  Downloading langchain_google_genai-2.0.4-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading langchain_google_genai-2.0.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "  Downloading langchain_google_genai-2.0.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "  Downloading langchain_google_genai-2.0.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "  Downloading langchain_google_genai-2.0.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "  Downloading langchain_google_genai-1.0.10-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading langchain_google_genai-1.0.9-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading langchain_google_genai-1.0.8-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading langchain_google_genai-1.0.7-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading langchain_google_genai-1.0.6-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading langchain_google_genai-1.0.5-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading langchain_google_genai-1.0.4-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading langchain_google_genai-1.0.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading langchain_google_genai-1.0.2-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading langchain_google_genai-1.0.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading langchain_google_genai-0.0.11-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading langchain_google_genai-0.0.9-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading langchain_google_genai-0.0.8-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading langchain_google_genai-0.0.7-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading langchain_google_genai-0.0.6-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading langchain_google_genai-0.0.5-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading langchain_google_genai-0.0.4-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading langchain_google_genai-0.0.3-py3-none-any.whl.metadata (2.4 kB)\n",
      "  Downloading langchain_google_genai-0.0.2-py3-none-any.whl.metadata (2.0 kB)\n",
      "  Downloading langchain_google_genai-0.0.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting google-ai-generativelanguage==0.4.0 (from google-generativeai->-r requirements.txt (line 23))\n",
      "  Downloading google_ai_generativelanguage-0.4.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting protobuf (from google-generativeai->-r requirements.txt (line 23))\n",
      "  Downloading protobuf-4.25.8-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
      "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai->-r requirements.txt (line 22))\n",
      "  Using cached grpcio_status-1.76.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.75.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.75.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.74.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.73.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.73.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.72.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "INFO: pip is still looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached grpcio_status-1.72.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.71.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.70.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.69.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.68.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading grpcio_status-1.68.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.67.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.67.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.66.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.66.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.66.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.65.5-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.65.4-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.65.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.65.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.64.3-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.64.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.64.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.63.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.63.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.62.3-py3-none-any.whl.metadata (1.3 kB)\n",
      "INFO: pip is looking at multiple versions of langchain-huggingface to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-huggingface (from -r requirements.txt (line 26))\n",
      "  Downloading langchain_huggingface-1.1.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.33.4 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain-huggingface->-r requirements.txt (line 26)) (0.36.0)\n",
      "Requirement already satisfied: tokenizers<1.0.0,>=0.19.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain-huggingface->-r requirements.txt (line 26)) (0.22.1)\n",
      "Requirement already satisfied: filelock in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface->-r requirements.txt (line 26)) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface->-r requirements.txt (line 26)) (2025.10.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from sentence-transformers->-r requirements.txt (line 27)) (4.57.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from sentence-transformers->-r requirements.txt (line 27)) (2.9.1)\n",
      "Requirement already satisfied: scikit-learn in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from sentence-transformers->-r requirements.txt (line 27)) (1.7.2)\n",
      "Requirement already satisfied: scipy in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from sentence-transformers->-r requirements.txt (line 27)) (1.16.3)\n",
      "Requirement already satisfied: Pillow in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from sentence-transformers->-r requirements.txt (line 27)) (12.0.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers->-r requirements.txt (line 27)) (0.7.0)\n",
      "Requirement already satisfied: build>=1.0.3 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 40)) (1.3.0)\n",
      "Requirement already satisfied: pybase64>=1.4.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 40)) (1.4.2)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 40)) (0.38.0)\n",
      "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 40)) (5.4.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 40)) (1.23.2)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 40)) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 40)) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 40)) (1.38.0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 40)) (0.48.9)\n",
      "Requirement already satisfied: overrides>=7.3.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 40)) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 40)) (6.5.2)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 40)) (5.0.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 40)) (0.20.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 40)) (34.1.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 40)) (5.2.0)\n",
      "Requirement already satisfied: rich>=10.11.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 40)) (14.2.0)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 40)) (4.25.1)\n",
      "Requirement already satisfied: six>=1.5 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb->-r requirements.txt (line 40)) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb->-r requirements.txt (line 40)) (2.9.0.post0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb->-r requirements.txt (line 40)) (2.2.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from beautifulsoup4->-r requirements.txt (line 57)) (2.8)\n",
      "Requirement already satisfied: jupyter-console in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from jupyter->-r requirements.txt (line 73)) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from jupyter->-r requirements.txt (line 73)) (7.16.6)\n",
      "Requirement already satisfied: ipywidgets in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from jupyter->-r requirements.txt (line 73)) (8.1.8)\n",
      "Requirement already satisfied: jupyterlab in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from jupyter->-r requirements.txt (line 73)) (4.5.0)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from notebook->-r requirements.txt (line 74)) (2.17.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.28.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from notebook->-r requirements.txt (line 74)) (2.28.0)\n",
      "Requirement already satisfied: notebook-shim<0.3,>=0.2 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from notebook->-r requirements.txt (line 74)) (0.2.4)\n",
      "Requirement already satisfied: tornado>=6.2.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from notebook->-r requirements.txt (line 74)) (6.5.2)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 74)) (25.1.0)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 74)) (3.1.6)\n",
      "Requirement already satisfied: jupyter-client>=7.4.4 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 74)) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 74)) (5.9.1)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 74)) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 74)) (0.5.3)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 74)) (5.10.4)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 74)) (0.23.1)\n",
      "Requirement already satisfied: pywinpty>=2.0.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 74)) (3.0.2)\n",
      "Requirement already satisfied: pyzmq>=24 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 74)) (27.1.0)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 74)) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 74)) (0.18.1)\n",
      "Requirement already satisfied: traitlets>=5.6.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 74)) (5.14.3)\n",
      "Requirement already satisfied: websocket-client>=1.7 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 74)) (1.9.0)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from jupyterlab->jupyter->-r requirements.txt (line 73)) (2.0.5)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from jupyterlab->jupyter->-r requirements.txt (line 73)) (2.3.0)\n",
      "Requirement already satisfied: setuptools>=41.1.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from jupyterlab->jupyter->-r requirements.txt (line 73)) (80.9.0)\n",
      "Requirement already satisfied: babel>=2.10 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from jupyterlab-server<3,>=2.28.0->notebook->-r requirements.txt (line 74)) (2.17.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from jupyterlab-server<3,>=2.28.0->notebook->-r requirements.txt (line 74)) (0.12.1)\n",
      "Requirement already satisfied: comm>=0.1.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from ipykernel->-r requirements.txt (line 75)) (0.2.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from ipykernel->-r requirements.txt (line 75)) (1.8.17)\n",
      "Requirement already satisfied: ipython>=7.23.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from ipykernel->-r requirements.txt (line 75)) (9.7.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from ipykernel->-r requirements.txt (line 75)) (0.2.1)\n",
      "Requirement already satisfied: nest-asyncio>=1.4 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from ipykernel->-r requirements.txt (line 75)) (1.6.0)\n",
      "Requirement already satisfied: psutil>=5.7 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from ipykernel->-r requirements.txt (line 75)) (7.1.3)\n",
      "Requirement already satisfied: argon2-cffi-bindings in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 74)) (25.1.0)\n",
      "Requirement already satisfied: pyproject_hooks in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from build>=1.0.3->chromadb->-r requirements.txt (line 40)) (1.2.0)\n",
      "Requirement already satisfied: colorama in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from build>=1.0.3->chromadb->-r requirements.txt (line 40)) (0.4.6)\n",
      "Requirement already satisfied: decorator>=4.3.2 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 75)) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers>=1.0.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 75)) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.18.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 75)) (0.19.2)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 75)) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.11.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 75)) (2.19.2)\n",
      "Requirement already satisfied: stack_data>=0.6.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 75)) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel->-r requirements.txt (line 75)) (0.2.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from jedi>=0.18.1->ipython>=7.23.1->ipykernel->-r requirements.txt (line 75)) (0.8.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from jinja2>=3.0.3->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 74)) (3.0.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from jsonschema>=4.19.0->chromadb->-r requirements.txt (line 40)) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from jsonschema>=4.19.0->chromadb->-r requirements.txt (line 40)) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from jsonschema>=4.19.0->chromadb->-r requirements.txt (line 40)) (0.29.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 74)) (4.5.0)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 74)) (4.0.0)\n",
      "Requirement already satisfied: rfc3339-validator in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 74)) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 74)) (0.1.1)\n",
      "Requirement already satisfied: fqdn in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 74)) (1.5.1)\n",
      "Requirement already satisfied: isoduration in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 74)) (20.11.0)\n",
      "Requirement already satisfied: rfc3987-syntax>=1.1.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 74)) (1.1.0)\n",
      "Requirement already satisfied: uri-template in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 74)) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 74)) (25.10.0)\n",
      "Requirement already satisfied: requests-oauthlib in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 40)) (2.0.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 40)) (0.10)\n",
      "Requirement already satisfied: bleach!=5.0.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter->-r requirements.txt (line 73)) (6.3.0)\n",
      "Requirement already satisfied: defusedxml in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 73)) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 73)) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 73)) (3.1.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 73)) (0.10.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 73)) (1.5.1)\n",
      "Requirement already satisfied: webencodings in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter->-r requirements.txt (line 73)) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter->-r requirements.txt (line 73)) (1.4.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 74)) (2.21.2)\n",
      "Requirement already satisfied: coloredlogs in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 40)) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 40)) (25.9.23)\n",
      "Requirement already satisfied: sympy in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 40)) (1.14.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb->-r requirements.txt (line 40)) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb->-r requirements.txt (line 40)) (3.23.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.38.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 40)) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.38.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 40)) (1.38.0)\n",
      "INFO: pip is looking at multiple versions of opentelemetry-proto to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.38.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 40))\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb->-r requirements.txt (line 40))\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.38.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.37.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.37.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.37.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.37.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_proto-1.37.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_sdk-1.37.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.36.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.36.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.36.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_proto-1.36.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_sdk-1.36.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.35.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.35.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.35.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.35.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_proto-1.35.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_sdk-1.35.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.34.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.34.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.34.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_proto-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_sdk-1.34.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.34.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.34.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.34.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.34.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_proto-1.34.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "INFO: pip is still looking at multiple versions of opentelemetry-proto to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.33.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 40))\n",
      "  Downloading deprecated-1.3.1-py2.py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.33.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.33.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.33.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_proto-1.33.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_sdk-1.33.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.33.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.33.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.33.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.33.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_proto-1.33.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.32.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.32.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.32.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.32.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_proto-1.32.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_sdk-1.32.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.32.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.32.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.32.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.32.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_proto-1.32.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.31.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.31.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.31.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.31.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_proto-1.31.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_sdk-1.31.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.31.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.31.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.31.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.31.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_proto-1.31.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.30.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.30.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.30.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.30.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_proto-1.30.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_sdk-1.30.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.29.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.29.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.29.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.29.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_proto-1.29.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_sdk-1.29.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.28.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.28.2 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.28.2-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.28.2 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_proto-1.28.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_sdk-1.28.2-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.28.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.28.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.28.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.28.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_proto-1.28.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.28.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.28.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.28.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.28.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_proto-1.28.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.27.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.27.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.27.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.27.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_proto-1.27.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_sdk-1.27.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_api-1.27.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.48b0 (from opentelemetry-sdk>=1.2.0->chromadb->-r requirements.txt (line 40))\n",
      "  Downloading opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting importlib-metadata<=8.4.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb->-r requirements.txt (line 40))\n",
      "  Downloading importlib_metadata-8.4.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting wrapt<3,>=1.10 (from deprecated>=1.2.6->opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 40))\n",
      "  Downloading wrapt-2.0.1-cp313-cp313-win_amd64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: lark>=1.2.2 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 74)) (1.3.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from rich>=10.11.0->chromadb->-r requirements.txt (line 40)) (4.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb->-r requirements.txt (line 40)) (0.1.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel->-r requirements.txt (line 75)) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel->-r requirements.txt (line 75)) (3.0.1)\n",
      "Requirement already satisfied: pure-eval in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel->-r requirements.txt (line 75)) (0.2.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers->-r requirements.txt (line 27)) (3.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 40)) (1.3.0)\n",
      "Requirement already satisfied: click>=8.0.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from typer>=0.9.0->chromadb->-r requirements.txt (line 40)) (8.3.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from typer>=0.9.0->chromadb->-r requirements.txt (line 40)) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 40)) (0.7.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 40)) (1.1.1)\n",
      "Requirement already satisfied: websockets>=10.4 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 40)) (15.0.1)\n",
      "Requirement already satisfied: cffi>=1.0.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 74)) (2.0.0)\n",
      "Requirement already satisfied: pycparser in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 74)) (2.23)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 40)) (10.0)\n",
      "Requirement already satisfied: pyreadline3 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 40)) (3.5.4)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from ipywidgets->jupyter->-r requirements.txt (line 73)) (4.0.15)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from ipywidgets->jupyter->-r requirements.txt (line 73)) (3.0.16)\n",
      "Requirement already satisfied: arrow>=0.15.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 74)) (1.4.0)\n",
      "Requirement already satisfied: tzdata in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 74)) (2025.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 40)) (3.3.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from scikit-learn->sentence-transformers->-r requirements.txt (line 27)) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from scikit-learn->sentence-transformers->-r requirements.txt (line 27)) (3.6.0)\n",
      "Downloading langchain_google_genai-0.0.1-py3-none-any.whl (8.5 kB)\n",
      "Downloading google_generativeai-0.3.2-py3-none-any.whl (146 kB)\n",
      "Downloading google_ai_generativelanguage-0.4.0-py3-none-any.whl (598 kB)\n",
      "   ---------------------------------------- 0.0/598.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 598.7/598.7 kB 35.5 MB/s  0:00:00\n",
      "Downloading grpcio_status-1.62.3-py3-none-any.whl (14 kB)\n",
      "Downloading protobuf-4.25.8-cp310-abi3-win_amd64.whl (413 kB)\n",
      "Downloading langchain_huggingface-1.1.0-py3-none-any.whl (29 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_grpc-1.27.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.27.0-py3-none-any.whl (52 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.27.0-py3-none-any.whl (17 kB)\n",
      "Downloading opentelemetry_sdk-1.27.0-py3-none-any.whl (110 kB)\n",
      "Downloading opentelemetry_api-1.27.0-py3-none-any.whl (63 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl (149 kB)\n",
      "Downloading importlib_metadata-8.4.0-py3-none-any.whl (26 kB)\n",
      "Downloading deprecated-1.3.1-py2.py3-none-any.whl (11 kB)\n",
      "Downloading wrapt-2.0.1-cp313-cp313-win_amd64.whl (60 kB)\n",
      "Installing collected packages: wrapt, protobuf, importlib-metadata, opentelemetry-proto, deprecated, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, grpcio-status, opentelemetry-semantic-conventions, opentelemetry-sdk, langchain-huggingface, google-ai-generativelanguage, opentelemetry-exporter-otlp-proto-grpc, google-generativeai, langchain-google-genai\n",
      "\n",
      "  Attempting uninstall: protobuf\n",
      "\n",
      "    Found existing installation: protobuf 5.29.5\n",
      "\n",
      "    Uninstalling protobuf-5.29.5:\n",
      "\n",
      "      Successfully uninstalled protobuf-5.29.5\n",
      "\n",
      "   -- -------------------------------------  1/15 [protobuf]\n",
      "   -- -------------------------------------  1/15 [protobuf]\n",
      "   -- -------------------------------------  1/15 [protobuf]\n",
      "   -- -------------------------------------  1/15 [protobuf]\n",
      "   -- -------------------------------------  1/15 [protobuf]\n",
      "   -- -------------------------------------  1/15 [protobuf]\n",
      "   -- -------------------------------------  1/15 [protobuf]\n",
      "   -- -------------------------------------  1/15 [protobuf]\n",
      "   -- -------------------------------------  1/15 [protobuf]\n",
      "   -- -------------------------------------  1/15 [protobuf]\n",
      "   -- -------------------------------------  1/15 [protobuf]\n",
      "   -- -------------------------------------  1/15 [protobuf]\n",
      "   -- -------------------------------------  1/15 [protobuf]\n",
      "   -- -------------------------------------  1/15 [protobuf]\n",
      "   -- -------------------------------------  1/15 [protobuf]\n",
      "   -- -------------------------------------  1/15 [protobuf]\n",
      "   -- -------------------------------------  1/15 [protobuf]\n",
      "   -- -------------------------------------  1/15 [protobuf]\n",
      "   -- -------------------------------------  1/15 [protobuf]\n",
      "  Attempting uninstall: importlib-metadata\n",
      "   -- -------------------------------------  1/15 [protobuf]\n",
      "    Found existing installation: importlib_metadata 8.7.0\n",
      "   -- -------------------------------------  1/15 [protobuf]\n",
      "    Uninstalling importlib_metadata-8.7.0:\n",
      "   -- -------------------------------------  1/15 [protobuf]\n",
      "      Successfully uninstalled importlib_metadata-8.7.0\n",
      "   -- -------------------------------------  1/15 [protobuf]\n",
      "  Attempting uninstall: opentelemetry-proto\n",
      "   -- -------------------------------------  1/15 [protobuf]\n",
      "    Found existing installation: opentelemetry-proto 1.38.0\n",
      "   -- -------------------------------------  1/15 [protobuf]\n",
      "    Uninstalling opentelemetry-proto-1.38.0:\n",
      "   -- -------------------------------------  1/15 [protobuf]\n",
      "      Successfully uninstalled opentelemetry-proto-1.38.0\n",
      "   -- -------------------------------------  1/15 [protobuf]\n",
      "   -------- -------------------------------  3/15 [opentelemetry-proto]\n",
      "  Attempting uninstall: opentelemetry-exporter-otlp-proto-common\n",
      "   -------- -------------------------------  3/15 [opentelemetry-proto]\n",
      "    Found existing installation: opentelemetry-exporter-otlp-proto-common 1.38.0\n",
      "   -------- -------------------------------  3/15 [opentelemetry-proto]\n",
      "    Uninstalling opentelemetry-exporter-otlp-proto-common-1.38.0:\n",
      "   -------- -------------------------------  3/15 [opentelemetry-proto]\n",
      "      Successfully uninstalled opentelemetry-exporter-otlp-proto-common-1.38.0\n",
      "   -------- -------------------------------  3/15 [opentelemetry-proto]\n",
      "  Attempting uninstall: opentelemetry-api\n",
      "   -------- -------------------------------  3/15 [opentelemetry-proto]\n",
      "    Found existing installation: opentelemetry-api 1.38.0\n",
      "   -------- -------------------------------  3/15 [opentelemetry-proto]\n",
      "    Uninstalling opentelemetry-api-1.38.0:\n",
      "   -------- -------------------------------  3/15 [opentelemetry-proto]\n",
      "      Successfully uninstalled opentelemetry-api-1.38.0\n",
      "   -------- -------------------------------  3/15 [opentelemetry-proto]\n",
      "   ---------------- -----------------------  6/15 [opentelemetry-api]\n",
      "  Attempting uninstall: grpcio-status\n",
      "   ---------------- -----------------------  6/15 [opentelemetry-api]\n",
      "    Found existing installation: grpcio-status 1.71.2\n",
      "   ---------------- -----------------------  6/15 [opentelemetry-api]\n",
      "    Uninstalling grpcio-status-1.71.2:\n",
      "   ---------------- -----------------------  6/15 [opentelemetry-api]\n",
      "      Successfully uninstalled grpcio-status-1.71.2\n",
      "   ---------------- -----------------------  6/15 [opentelemetry-api]\n",
      "  Attempting uninstall: opentelemetry-semantic-conventions\n",
      "   ---------------- -----------------------  6/15 [opentelemetry-api]\n",
      "    Found existing installation: opentelemetry-semantic-conventions 0.59b0\n",
      "   ---------------- -----------------------  6/15 [opentelemetry-api]\n",
      "    Uninstalling opentelemetry-semantic-conventions-0.59b0:\n",
      "   ---------------- -----------------------  6/15 [opentelemetry-api]\n",
      "      Successfully uninstalled opentelemetry-semantic-conventions-0.59b0\n",
      "   ---------------- -----------------------  6/15 [opentelemetry-api]\n",
      "   ----------------- ---------------  8/15 [opentelemetry-semantic-conventions]\n",
      "  Attempting uninstall: opentelemetry-sdk\n",
      "   ----------------- ---------------  8/15 [opentelemetry-semantic-conventions]\n",
      "    Found existing installation: opentelemetry-sdk 1.38.0\n",
      "   ----------------- ---------------  8/15 [opentelemetry-semantic-conventions]\n",
      "    Uninstalling opentelemetry-sdk-1.38.0:\n",
      "   ----------------- ---------------  8/15 [opentelemetry-semantic-conventions]\n",
      "      Successfully uninstalled opentelemetry-sdk-1.38.0\n",
      "   ----------------- ---------------  8/15 [opentelemetry-semantic-conventions]\n",
      "   ------------------------ ---------------  9/15 [opentelemetry-sdk]\n",
      "  Attempting uninstall: langchain-huggingface\n",
      "   ------------------------ ---------------  9/15 [opentelemetry-sdk]\n",
      "    Found existing installation: langchain-huggingface 0.3.1\n",
      "   ------------------------ ---------------  9/15 [opentelemetry-sdk]\n",
      "    Uninstalling langchain-huggingface-0.3.1:\n",
      "   ------------------------ ---------------  9/15 [opentelemetry-sdk]\n",
      "      Successfully uninstalled langchain-huggingface-0.3.1\n",
      "   ------------------------ ---------------  9/15 [opentelemetry-sdk]\n",
      "   -------------------------- ------------- 10/15 [langchain-huggingface]\n",
      "  Attempting uninstall: google-ai-generativelanguage\n",
      "   -------------------------- ------------- 10/15 [langchain-huggingface]\n",
      "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
      "   -------------------------- ------------- 10/15 [langchain-huggingface]\n",
      "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
      "   -------------------------- ------------- 10/15 [langchain-huggingface]\n",
      "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
      "   -------------------------- ------------- 10/15 [langchain-huggingface]\n",
      "   ---------------------------- ---------- 11/15 [google-ai-generativelanguage]\n",
      "   ---------------------------- ---------- 11/15 [google-ai-generativelanguage]\n",
      "   ---------------------------- ---------- 11/15 [google-ai-generativelanguage]\n",
      "   ---------------------------- ---------- 11/15 [google-ai-generativelanguage]\n",
      "  Attempting uninstall: opentelemetry-exporter-otlp-proto-grpc\n",
      "   ---------------------------- ---------- 11/15 [google-ai-generativelanguage]\n",
      "    Found existing installation: opentelemetry-exporter-otlp-proto-grpc 1.38.0\n",
      "   ---------------------------- ---------- 11/15 [google-ai-generativelanguage]\n",
      "    Uninstalling opentelemetry-exporter-otlp-proto-grpc-1.38.0:\n",
      "   ---------------------------- ---------- 11/15 [google-ai-generativelanguage]\n",
      "      Successfully uninstalled opentelemetry-exporter-otlp-proto-grpc-1.38.0\n",
      "   ---------------------------- ---------- 11/15 [google-ai-generativelanguage]\n",
      "   ----------------------- ----- 12/15 [opentelemetry-exporter-otlp-proto-grpc]\n",
      "  Attempting uninstall: google-generativeai\n",
      "   ----------------------- ----- 12/15 [opentelemetry-exporter-otlp-proto-grpc]\n",
      "    Found existing installation: google-generativeai 0.8.5\n",
      "   ----------------------- ----- 12/15 [opentelemetry-exporter-otlp-proto-grpc]\n",
      "    Uninstalling google-generativeai-0.8.5:\n",
      "   ----------------------- ----- 12/15 [opentelemetry-exporter-otlp-proto-grpc]\n",
      "   ---------------------------------- ----- 13/15 [google-generativeai]\n",
      "   ---------------------------------- ----- 13/15 [google-generativeai]\n",
      "      Successfully uninstalled google-generativeai-0.8.5\n",
      "   ---------------------------------- ----- 13/15 [google-generativeai]\n",
      "   ---------------------------------- ----- 13/15 [google-generativeai]\n",
      "  Attempting uninstall: langchain-google-genai\n",
      "   ---------------------------------- ----- 13/15 [google-generativeai]\n",
      "    Found existing installation: langchain-google-genai 2.0.10\n",
      "   ---------------------------------- ----- 13/15 [google-generativeai]\n",
      "    Uninstalling langchain-google-genai-2.0.10:\n",
      "   ---------------------------------- ----- 13/15 [google-generativeai]\n",
      "   ------------------------------------- -- 14/15 [langchain-google-genai]\n",
      "      Successfully uninstalled langchain-google-genai-2.0.10\n",
      "   ------------------------------------- -- 14/15 [langchain-google-genai]\n",
      "   ---------------------------------------- 15/15 [langchain-google-genai]\n",
      "\n",
      "Successfully installed deprecated-1.3.1 google-ai-generativelanguage-0.4.0 google-generativeai-0.3.2 grpcio-status-1.62.3 importlib-metadata-8.4.0 langchain-google-genai-0.0.1 langchain-huggingface-1.1.0 opentelemetry-api-1.27.0 opentelemetry-exporter-otlp-proto-common-1.27.0 opentelemetry-exporter-otlp-proto-grpc-1.27.0 opentelemetry-proto-1.27.0 opentelemetry-sdk-1.27.0 opentelemetry-semantic-conventions-0.48b0 protobuf-4.25.8 wrapt-2.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'D:\\AiCode\\LcRAGBtCmp\\simple-rag-langchain\\lcrag_venv\\Lib\\site-packages\\google\\~upb'.\n",
      "  You can safely remove it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-ollama in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: langchain-chroma in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (0.2.6)\n",
      "Requirement already satisfied: chromadb in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (1.3.5)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain-ollama) (1.1.0)\n",
      "Requirement already satisfied: ollama<1.0.0,>=0.6.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain-ollama) (0.6.1)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-ollama) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-ollama) (0.4.46)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-ollama) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-ollama) (2.12.4)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-ollama) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-ollama) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-ollama) (4.15.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (0.25.0)\n",
      "Requirement already satisfied: anyio in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (4.11.0)\n",
      "Requirement already satisfied: certifi in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (1.0.9)\n",
      "Requirement already satisfied: idna in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (0.4.2)\n",
      "Requirement already satisfied: numpy>=2.1.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain-chroma) (2.3.5)\n",
      "Requirement already satisfied: build>=1.0.3 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from chromadb) (1.3.0)\n",
      "Requirement already satisfied: pybase64>=1.4.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from chromadb) (1.4.2)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.38.0)\n",
      "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from chromadb) (5.4.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from chromadb) (1.23.2)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from chromadb) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from chromadb) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from chromadb) (1.27.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from chromadb) (0.22.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from chromadb) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from chromadb) (1.76.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from chromadb) (5.0.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from chromadb) (0.20.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from chromadb) (34.1.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from chromadb) (5.2.0)\n",
      "Requirement already satisfied: rich>=10.11.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from chromadb) (14.2.0)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from chromadb) (4.25.1)\n",
      "Requirement already satisfied: six>=1.5 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (2.3.0)\n",
      "Requirement already satisfied: pyproject_hooks in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: colorama in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Requirement already satisfied: attrs>=22.2.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.29.0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.43.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: requests-oauthlib in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (6.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
      "Requirement already satisfied: coloredlogs in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (25.9.23)\n",
      "Requirement already satisfied: protobuf in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (4.25.8)\n",
      "Requirement already satisfied: sympy in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata<=8.4.0,>=6.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.4.0)\n",
      "Requirement already satisfied: zipp>=0.5 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from importlib-metadata<=8.4.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
      "Requirement already satisfied: wrapt<3,>=1.10 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from deprecated>=1.2.6->opentelemetry-api>=1.2.0->chromadb) (2.0.1)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.72.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.27.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.27.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.48b0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.48b0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from tokenizers>=0.13.2->chromadb) (0.36.0)\n",
      "Requirement already satisfied: filelock in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.10.0)\n",
      "Requirement already satisfied: click>=8.0.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from typer>=0.9.0->chromadb) (8.3.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.7.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.2.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
      "Requirement already satisfied: websockets>=10.4 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (1.3.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: pyreadline3 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb) (3.5.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages (run this once)\n",
    "%pip install langchain langchain-core langchain-community langchain-text-splitters\n",
    "%pip install langchain-ollama langchain-chroma chromadb\n",
    "%pip install pypdf tiktoken\n",
    "\n",
    "# Or install from requirements.txt with additional packages:\n",
    "%pip install -r requirements.txt\n",
    "%pip install langchain-ollama langchain-chroma chromadb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Ollama Models:\n",
    "\n",
    "Run these commands in your terminal (if you haven't already):\n",
    "\n",
    "```bash\n",
    "# Embedding model (choose one or both)\n",
    "ollama pull nomic-embed-text    # Recommended: 274 MB\n",
    "ollama pull embeddinggemma      # Alternative: 621 MB\n",
    "\n",
    "# LLM for generation\n",
    "ollama pull gemma3:1b          # Small & fast: 815 MB\n",
    "```\n",
    "\n",
    "**Note**: You already have these models downloaded! ‚úì"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì All imports successful!\n",
      "‚úì Ready for local offline RAG!\n",
      "\n",
      "Python version: 3.13.5 | packaged by Anaconda, Inc. | (main, Jun 12 2025, 16:37:03) [MSC v.1929 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# LangChain Document Loaders\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# LangChain Text Splitters\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Ollama Integration\n",
    "from langchain_ollama import OllamaEmbeddings, ChatOllama\n",
    "\n",
    "# ChromaDB Vector Store\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# LangChain Core Components\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "print(\"‚úì All imports successful!\")\n",
    "print(\"‚úì Ready for local offline RAG!\")\n",
    "print(f\"\\nPython version: {sys.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Verify Ollama Installation\n",
    "\n",
    "Let's check that Ollama is running and our models are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                        ID              SIZE      MODIFIED          \n",
      "gemma3:latest               a2af6cc3eb7f    3.3 GB    22 minutes ago       \n",
      "mxbai-embed-large:latest    468836162de7    669 MB    25 minutes ago       \n",
      "bge-m3:latest               790764642607    1.2 GB    59 minutes ago       \n",
      "nomic-embed-text:latest     0a109f422b47    274 MB    About an hour ago    \n",
      "llama3.2:latest             a80c4f17acd5    2.0 GB    3 weeks ago          \n",
      "gemma3:4b                   a2af6cc3eb7f    3.3 GB    3 weeks ago          \n"
     ]
    }
   ],
   "source": [
    "# Check Ollama is running and list available models\n",
    "!ollama list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Ollama connection...\n",
      "\n",
      "‚úì Ollama is working!\n",
      "Response: Hello! I am running locally on your machine! üòä\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test Ollama connection with a simple query\n",
    "print(\"Testing Ollama connection...\\n\")\n",
    "\n",
    "try:\n",
    "    test_llm = ChatOllama(model=\"gemma3:4b\", temperature=0)\n",
    "    # bge-m3:latest \n",
    "    response = test_llm.invoke(\"Say 'Hello! I am running locally on your machine!'\")\n",
    "    \n",
    "    print(\"‚úì Ollama is working!\")\n",
    "    print(f\"Response: {response.content}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚úó Error connecting to Ollama: {e}\")\n",
    "    print(\"\\nMake sure Ollama is running. Try: ollama serve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load PDF Documents\n",
    "\n",
    "Load your PDF documents for the RAG system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Loaded 15 pages from 'attention.pdf'\n",
      "\n",
      "--- First Page Preview ---\n",
      "Content (first 300 chars): Provided proper attribution is provided, Google hereby grants permission to\n",
      "reproduce the tables and figures in this paper solely for use in journalistic or\n",
      "scholarly works.\n",
      "Attention Is All You Need\n",
      "Ashish Vaswani‚àó\n",
      "Google Brain\n",
      "avaswani@google.com\n",
      "Noam Shazeer‚àó\n",
      "Google Brain\n",
      "noam@google.com\n",
      "Niki Par...\n",
      "\n",
      "Metadata: {'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}\n",
      "\n",
      "Total characters: 39,587\n"
     ]
    }
   ],
   "source": [
    "# ===== CONFIGURATION: Update this path to your PDF file =====\n",
    "pdf_path = \"attention.pdf\"  # Change this to your PDF file path\n",
    "# =============================================================\n",
    "\n",
    "# Check if file exists\n",
    "if not os.path.exists(pdf_path):\n",
    "    print(f\"‚ö†Ô∏è  ERROR: File '{pdf_path}' not found!\")\n",
    "    print(\"Please update the pdf_path variable with your PDF file location.\")\n",
    "else:\n",
    "    # Load the PDF\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    documents = loader.load()\n",
    "    \n",
    "    # Display information\n",
    "    print(f\"‚úì Loaded {len(documents)} pages from '{pdf_path}'\")\n",
    "    print(f\"\\n--- First Page Preview ---\")\n",
    "    print(f\"Content (first 300 chars): {documents[0].page_content[:300]}...\")\n",
    "    print(f\"\\nMetadata: {documents[0].metadata}\")\n",
    "    print(f\"\\nTotal characters: {sum(len(doc.page_content) for doc in documents):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Load Multiple PDFs from a Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 PDF files\n",
      "\n",
      "  ‚úì Loaded 15 pages from attention.pdf\n",
      "  ‚úì Loaded 19 pages from rag.pdf\n",
      "  ‚úì Loaded 21 pages from ragsurvey.pdf\n",
      "\n",
      "Total pages loaded: 55\n"
     ]
    }
   ],
   "source": [
    "# Uncomment to load multiple PDFs from a directory\n",
    "\n",
    "pdf_directory = \"./pdfs\"\n",
    "all_documents = []\n",
    "\n",
    "if os.path.exists(pdf_directory):\n",
    "    pdf_files = list(Path(pdf_directory).glob(\"*.pdf\"))\n",
    "    print(f\"Found {len(pdf_files)} PDF files\\n\")\n",
    "    \n",
    "    for pdf_file in pdf_files:\n",
    "        loader = PyPDFLoader(str(pdf_file))\n",
    "        docs = loader.load()\n",
    "        all_documents.extend(docs)\n",
    "        print(f\"  ‚úì Loaded {len(docs)} pages from {pdf_file.name}\")\n",
    "    \n",
    "    print(f\"\\nTotal pages loaded: {len(all_documents)}\")\n",
    "    documents = all_documents  # Use this for the rest of the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Split Documents into Chunks\n",
    "\n",
    "Break documents into smaller chunks for better retrieval precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Split 55 documents into 267 chunks\n",
      "\n",
      "Average chunk size: 898 characters\n",
      "\n",
      "--- Chunk Examples ---\n",
      "\n",
      "Chunk 1 (length: 986 chars):\n",
      "Provided proper attribution is provided, Google hereby grants permission to\n",
      "reproduce the tables and figures in this paper solely for use in journalistic or\n",
      "scholarly works.\n",
      "Attention Is All You Need\n",
      "...\n",
      "\n",
      "Chunk 2 (length: 944 chars):\n",
      "based solely on attention mechanisms, dispensing with recurrence and convolutions\n",
      "entirely. Experiments on two machine translation tasks show these models to\n",
      "be superior in quality while being more pa...\n",
      "\n",
      "Chunk 3 (length: 986 chars):\n",
      "‚àóEqual contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started\n",
      "the effort to evaluate this idea. Ashish, with Illia, designed and implemented the first Tra...\n"
     ]
    }
   ],
   "source": [
    "# Initialize text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1024,        # Characters per chunk\n",
    "    chunk_overlap=128,      # Overlap to maintain context\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]  # Split on paragraphs, then lines, etc.\n",
    ")\n",
    "\n",
    "# Split documents\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "# Display results\n",
    "avg_chunk_size = sum(len(chunk.page_content) for chunk in chunks) / len(chunks)\n",
    "\n",
    "print(f\"‚úì Split {len(documents)} documents into {len(chunks)} chunks\")\n",
    "print(f\"\\nAverage chunk size: {avg_chunk_size:.0f} characters\")\n",
    "\n",
    "# Preview chunks\n",
    "print(f\"\\n--- Chunk Examples ---\")\n",
    "for i, chunk in enumerate(chunks[:3]):\n",
    "    print(f\"\\nChunk {i+1} (length: {len(chunk.page_content)} chars):\")\n",
    "    print(f\"{chunk.page_content[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create Embeddings (Primary: Nomic-Embed-Text)\n",
    "\n",
    "### About Nomic-Embed-Text:\n",
    "- **Size**: 274 MB\n",
    "- **Dimensions**: 768\n",
    "- **Performance**: State-of-the-art for local embeddings\n",
    "- **Speed**: Fast inference\n",
    "- **License**: Open source (Apache 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing nomic-embed-text embeddings...\n",
      "\n",
      "‚úì Embeddings model: nomic-embed-text\n",
      "‚úì Embedding dimension: 768\n",
      "‚úì Sample embedding (first 10 values): [0.03251289, 0.060831312, -0.1661455, -0.08210702, 0.043301575, -0.025996638, 0.051529177, -0.015186348, -0.008282056, -0.028375432]\n",
      "\n",
      "‚ÑπÔ∏è  Each chunk will be converted to a 768-dimensional vector\n",
      "‚ÑπÔ∏è  All processing happens locally on your machine!\n"
     ]
    }
   ],
   "source": [
    "# Initialize Ollama Embeddings with nomic-embed-text\n",
    "embeddings = OllamaEmbeddings(\n",
    "    model=\"nomic-embed-text\",   # Embeddings model mxbai-embed-large \n",
    "    # base_url=\"http://localhost:11434\"  # Default Ollama URL\n",
    ")\n",
    "\n",
    "# Test embeddings\n",
    "print(\"Testing nomic-embed-text embeddings...\\n\")\n",
    "sample_text = \"This is a test sentence for embeddings.\"\n",
    "sample_embedding = embeddings.embed_query(sample_text)\n",
    "\n",
    "print(f\"‚úì Embeddings model: nomic-embed-text\")\n",
    "print(f\"‚úì Embedding dimension: {len(sample_embedding)}\")\n",
    "print(f\"‚úì Sample embedding (first 10 values): {sample_embedding[:10]}\")\n",
    "print(f\"\\n‚ÑπÔ∏è  Each chunk will be converted to a {len(sample_embedding)}-dimensional vector\")\n",
    "print(f\"‚ÑπÔ∏è  All processing happens locally on your machine!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Alternative: EmbeddingGemma (Optional)\n",
    "\n",
    "### About EmbeddingGemma:\n",
    "- **Size**: 621 MB (larger than nomic)\n",
    "- **Dimensions**: 768\n",
    "- **Optimized for**: Google Gemma models\n",
    "- **Use case**: Better alignment with Gemma LLMs\n",
    "\n",
    "**Uncomment the code below to use embeddinggemma instead:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Alternative: Use embeddinggemma instead\n",
    "# embeddings = OllamaEmbeddings(\n",
    "#     model=\"embeddinggemma:latest\"\n",
    "# )\n",
    "\n",
    "# # Test embeddings\n",
    "# print(\"Testing embeddinggemma embeddings...\\n\")\n",
    "# sample_text = \"This is a test sentence for embeddings.\"\n",
    "# sample_embedding = embeddings.embed_query(sample_text)\n",
    "\n",
    "# print(f\"‚úì Embeddings model: embeddinggemma\")\n",
    "# print(f\"‚úì Embedding dimension: {len(sample_embedding)}\")\n",
    "# print(f\"‚úì Sample embedding (first 10 values): {sample_embedding[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Create ChromaDB Vector Store\n",
    "\n",
    "### Why ChromaDB?\n",
    "- **Local & Persistent**: Stores vectors on disk\n",
    "- **Python 3.13 Compatible**: Works with latest Python\n",
    "- **Easy to Use**: Simple API\n",
    "- **Open Source**: Free and fully featured\n",
    "\n",
    "**Note**: This step may take a minute as it processes all chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ChromaDB vector store from 267 chunks...\n",
      "This may take a minute...\n",
      "\n",
      "‚úì ChromaDB vector store created successfully!\n",
      "‚úì Indexed 267 document chunks\n",
      "‚úì Stored at: ./chroma_db\n",
      "\n",
      "‚ÑπÔ∏è  Vector store persisted to disk - you can reload it later!\n"
     ]
    }
   ],
   "source": [
    "# Create ChromaDB vector store\n",
    "print(f\"Creating ChromaDB vector store from {len(chunks)} chunks...\")\n",
    "print(\"This may take a minute...\\n\")\n",
    "\n",
    "# Set persistent directory\n",
    "persist_directory = \"./chroma_db\"\n",
    "\n",
    "# Create vector store\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=persist_directory,\n",
    "    collection_name=\"local_rag_collection\"\n",
    ")\n",
    "\n",
    "print(f\"‚úì ChromaDB vector store created successfully!\")\n",
    "print(f\"‚úì Indexed {len(chunks)} document chunks\")\n",
    "print(f\"‚úì Stored at: {persist_directory}\")\n",
    "print(f\"\\n‚ÑπÔ∏è  Vector store persisted to disk - you can reload it later!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Existing Vector Store (Optional)\n",
    "\n",
    "If you've already created the vector store, you can load it instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncomment to load existing vector store\n",
    "# persist_directory = \"./chroma_db\"\n",
    "\n",
    "# vectorstore = Chroma(\n",
    "#     persist_directory=persist_directory,\n",
    "#     embedding_function=embeddings,\n",
    "#     collection_name=\"local_rag_collection\"\n",
    "# )\n",
    "\n",
    "# print(f\"‚úì Loaded existing vector store from '{persist_directory}'\")\n",
    "# print(f\"‚úì Collection: local_rag_collection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Create Retriever and Test\n",
    "\n",
    "The retriever finds the most relevant chunks for a given query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Retriever configured successfully\n",
      "  - Search type: similarity\n",
      "  - Number of documents to retrieve (k): 4\n",
      "\n",
      "--- Retriever Test ---\n",
      "Query: 'What is the main topic of this document?'\n",
      "\n",
      "Retrieved 4 documents:\n",
      "\n",
      "Document 1:\n",
      "  Content preview: tion VII mainly discusses the challenges that RAG currently\n",
      "faces and its future development directions. At last, the paper\n",
      "concludes in Section VIII....\n",
      "  Source: Page 1\n",
      "\n",
      "Document 2:\n",
      "  Content preview: Jonathan Berant. Coarse-to-Ô¨Åne question answering for long documents. In Proceedings of the\n",
      "55th Annual Meeting of the Association for Computational L...\n",
      "  Source: Page 9\n",
      "\n",
      "Document 3:\n",
      "  Content preview: RAG, and Modular RAG, as showed in Figure 3. Despite\n",
      "RAG method are cost-effective and surpass the performance\n",
      "of the native LLM, they also exhibit se...\n",
      "  Source: Page 1\n",
      "\n",
      "Document 4:\n",
      "  Content preview: just the summary! topic-aware convolutional neural networks for ex-\n",
      "treme summarization,‚Äù arXiv preprint arXiv:1808.08745 , 2018.\n",
      "[154] S. Saha, J. A....\n",
      "  Source: Page 19\n"
     ]
    }
   ],
   "source": [
    "# Create retriever\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",    # Use cosine similarity\n",
    "    search_kwargs={\"k\": 4}        # Retrieve top 4 most relevant chunks\n",
    ")\n",
    "\n",
    "print(\"‚úì Retriever configured successfully\")\n",
    "print(f\"  - Search type: similarity\")\n",
    "print(f\"  - Number of documents to retrieve (k): 4\")\n",
    "\n",
    "# Test retrieval\n",
    "test_query = \"What is the main topic of this document?\"\n",
    "print(f\"\\n--- Retriever Test ---\")\n",
    "print(f\"Query: '{test_query}'\")\n",
    "\n",
    "retrieved_docs = retriever.invoke(test_query)\n",
    "\n",
    "print(f\"\\nRetrieved {len(retrieved_docs)} documents:\")\n",
    "for i, doc in enumerate(retrieved_docs):\n",
    "    print(f\"\\nDocument {i+1}:\")\n",
    "    print(f\"  Content preview: {doc.page_content[:150]}...\")\n",
    "    print(f\"  Source: Page {doc.metadata.get('page', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Configure Ollama LLM (Gemma3:1b)\n",
    "\n",
    "### About Gemma3:1b:\n",
    "- **Size**: 815 MB\n",
    "- **Parameters**: 1 billion\n",
    "- **Speed**: Very fast inference\n",
    "- **Quality**: Good for most Q&A tasks\n",
    "- **Memory**: Low RAM usage\n",
    "\n",
    "**Alternatives**: You can also use llama3.2 (2GB) or deepseek-r1 (4.7GB) for better quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì LLM configured successfully\n",
      "  - Model: gemma3:4b (local)\n",
      "  - Temperature: 0 (deterministic)\n",
      "\n",
      "LLM Test Response: Hello! I am Gemma running locally! üòä\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize Ollama LLM\n",
    "llm = ChatOllama(\n",
    "    model=\"gemma3:4b\",\n",
    "    temperature=0,          # Deterministic responses (0 = focused, 1 = creative)\n",
    "    # num_predict=2000,     # Max tokens to generate\n",
    "    # top_k=40,             # Top-k sampling\n",
    "    # top_p=0.9,            # Top-p (nucleus) sampling\n",
    ")\n",
    "\n",
    "print(\"‚úì LLM configured successfully\")\n",
    "print(f\"  - Model: gemma3:4b (local)\")\n",
    "print(f\"  - Temperature: 0 (deterministic)\")\n",
    "\n",
    "# Test LLM\n",
    "test_response = llm.invoke(\"Say 'Hello! I am Gemma running locally!'\")\n",
    "print(f\"\\nLLM Test Response: {test_response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Other Local Models (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Alternative: Use llama3.2 for better quality\n",
    "# llm = ChatOllama(\n",
    "#     model=\"llama3.2:latest\",\n",
    "#     temperature=0\n",
    "# )\n",
    "\n",
    "# # Alternative: Use deepseek-r1 for reasoning tasks\n",
    "# llm = ChatOllama(\n",
    "#     model=\"deepseek-r1:latest\",\n",
    "#     temperature=0\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Build RAG Chain (LangChain Expression Language)\n",
    "\n",
    "Combine retrieval and generation into a single pipeline using LCEL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì RAG chain created successfully using LCEL!\n",
      "\n",
      "RAG Pipeline Flow:\n",
      "  1. User provides a query\n",
      "  2. Retriever finds top 4 relevant chunks (local ChromaDB)\n",
      "  3. Chunks are formatted as context\n",
      "  4. Context + question formatted with prompt template\n",
      "  5. Local LLM (gemma3:1b) generates answer\n",
      "  6. Answer parsed and returned\n",
      "\n",
      "üîí Everything runs locally on your machine!\n"
     ]
    }
   ],
   "source": [
    "# Define prompt template\n",
    "system_prompt = (\n",
    "    \"You are a helpful assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer the question. \"\n",
    "    \"If you don't know the answer based on the context, say that you don't know. \"\n",
    "    \"Keep the answer concise and accurate.\\n\\n\"\n",
    "    \"Context: {context}\\n\\n\"\n",
    "    \"Question: {question}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(system_prompt)\n",
    "\n",
    "# Helper function to format documents\n",
    "def format_docs(docs):\n",
    "    \"\"\"Format retrieved documents into a single string.\"\"\"\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Build RAG chain using LCEL\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": retriever | format_docs,  # Retrieve and format docs\n",
    "        \"question\": RunnablePassthrough()      # Pass through the question\n",
    "    }\n",
    "    | prompt           # Format with prompt template\n",
    "    | llm              # Generate answer with local LLM\n",
    "    | StrOutputParser() # Parse output to string\n",
    ")\n",
    "\n",
    "print(\"‚úì RAG chain created successfully using LCEL!\")\n",
    "print(\"\\nRAG Pipeline Flow:\")\n",
    "print(\"  1. User provides a query\")\n",
    "print(\"  2. Retriever finds top 4 relevant chunks (local ChromaDB)\")\n",
    "print(\"  3. Chunks are formatted as context\")\n",
    "print(\"  4. Context + question formatted with prompt template\")\n",
    "print(\"  5. Local LLM (gemma3:1b) generates answer\")\n",
    "print(\"  6. Answer parsed and returned\")\n",
    "print(\"\\nüîí Everything runs locally on your machine!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Test RAG Pipeline with Example Queries\n",
    "\n",
    "Let's test our complete local RAG system!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is the main topic or contribution of this document?\n",
      "\n",
      "Processing locally...\n",
      "\n",
      "================================================================================\n",
      "ANSWER:\n",
      "================================================================================\n",
      "This document primarily discusses the RAG (Retrieval-Augmented Generation) research paradigm, its stages (Naive, Advanced, and Modular RAG), and its evolution, including its expansion to multi-modal data like images.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "SOURCE DOCUMENTS USED:\n",
      "================================================================================\n",
      "\n",
      "Document 1:\n",
      "  Page: 1\n",
      "  Content: tion VII mainly discusses the challenges that RAG currently\n",
      "faces and its future development directions. At last, the paper\n",
      "concludes in Section VIII.\n",
      "II. O VERVIEW OF RAG\n",
      "A typical application of RAG...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Document 2:\n",
      "  Page: 1\n",
      "  Content: RAG, and Modular RAG, as showed in Figure 3. Despite\n",
      "RAG method are cost-effective and surpass the performance\n",
      "of the native LLM, they also exhibit several limitations.\n",
      "The development of Advanced RAG...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Document 3:\n",
      "  Page: 6\n",
      "  Content: Document 1: his works are considered classics of American\n",
      "literature ... His wartime experiences formed the basis for his novel\n",
      "‚ÄùA Farewell to Arms‚Äù(1929) ...\n",
      "Document 2: ... artists of the 1920s ‚ÄùLos...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Document 4:\n",
      "  Page: 15\n",
      "  Content: 16\n",
      "Fig. 6. Summary of RAG ecosystem\n",
      "initial learning curve. 3) Specialization - optimizing RAG to\n",
      "better serve production environments.\n",
      "The mutual growth of RAG models and their technology\n",
      "stacks is e...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Example Query 1: General question\n",
    "query1 = \"What is the main topic or contribution of this document?\"\n",
    "\n",
    "print(f\"Query: {query1}\")\n",
    "print(\"\\nProcessing locally...\\n\")\n",
    "\n",
    "answer = rag_chain.invoke(query1)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ANSWER:\")\n",
    "print(\"=\" * 80)\n",
    "print(answer)\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "# Show source documents\n",
    "print(\"\\nSOURCE DOCUMENTS USED:\")\n",
    "print(\"=\" * 80)\n",
    "retrieved_docs = retriever.invoke(query1)\n",
    "for i, doc in enumerate(retrieved_docs):\n",
    "    print(f\"\\nDocument {i+1}:\")\n",
    "    print(f\"  Page: {doc.metadata.get('page', 'N/A')}\")\n",
    "    print(f\"  Content: {doc.page_content[:200]}...\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Can you summarize the key technical contributions or innovations mentioned?\n",
      "\n",
      "Processing locally...\n",
      "\n",
      "================================================================================\n",
      "ANSWER:\n",
      "================================================================================\n",
      "The key innovations include:\n",
      "\n",
      "*   Replacing RNNs with self-attention.\n",
      "*   Designing and implementing the first Transformer models.\n",
      "*   Scaled dot-product attention and multi-head attention.\n",
      "*   Incorporating external databases to bridge information gaps for LLMs.\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Example Query 2: Specific information extraction\n",
    "query2 = \"Can you summarize the key technical contributions or innovations mentioned?\"\n",
    "\n",
    "print(f\"Query: {query2}\")\n",
    "print(\"\\nProcessing locally...\\n\")\n",
    "\n",
    "answer = rag_chain.invoke(query2)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ANSWER:\")\n",
    "print(\"=\" * 80)\n",
    "print(answer)\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What specific details are mentioned about the methodology or approach?\n",
      "\n",
      "Processing locally...\n",
      "\n",
      "================================================================================\n",
      "ANSWER:\n",
      "================================================================================\n",
      "The methodology includes Naive RAG, RAG, Advanced RAG, and Modular RAG. Naive RAG is the earliest methodology, RAG provides a tailored textbook for information retrieval, and Advanced/Modular RAG address limitations of Naive RAG.\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Example Query 3: Your custom question\n",
    "custom_query = \"What specific details are mentioned about the methodology or approach?\"\n",
    "\n",
    "print(f\"Query: {custom_query}\")\n",
    "print(\"\\nProcessing locally...\\n\")\n",
    "\n",
    "answer = rag_chain.invoke(custom_query)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ANSWER:\")\n",
    "print(\"=\" * 80)\n",
    "print(answer)\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Interactive Q&A Session\n",
    "\n",
    "Ask your own questions to the RAG system!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Question: What are the main findings or results?\n",
      "================================================================================\n",
      "\n",
      "Answer: The main evaluation objectives include: Retrieval Quality and Generation Quality. Standard metrics from search engines and information retrieval systems are used to measure retrieval performance, and generation quality is assessed based on faithfulness, relevance, and non-harmfulness.\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The main evaluation objectives include: Retrieval Quality and Generation Quality. Standard metrics from search engines and information retrieval systems are used to measure retrieval performance, and generation quality is assessed based on faithfulness, relevance, and non-harmfulness.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Interactive Q&A\n",
    "def ask_question(question):\n",
    "    \"\"\"Ask a question to the RAG system.\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    answer = rag_chain.invoke(question)\n",
    "    \n",
    "    print(f\"\\nAnswer: {answer}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    return answer\n",
    "\n",
    "# Try it out!\n",
    "# Change the question below to ask anything about your document\n",
    "my_question = \"What are the main findings or results?\"\n",
    "ask_question(my_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Bonus: Compare Embedding Models (Optional)\n",
    "\n",
    "Compare retrieval results between nomic-embed-text and embeddinggemma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncomment to compare embedding models\n",
    "\n",
    "# print(\"Comparing embedding models...\\n\")\n",
    "\n",
    "# test_query = \"What is attention mechanism?\"\n",
    "\n",
    "# # Test with nomic-embed-text\n",
    "# print(\"=\" * 80)\n",
    "# print(\"Using nomic-embed-text:\")\n",
    "# print(\"=\" * 80)\n",
    "# embeddings_nomic = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "# vectorstore_nomic = Chroma.from_documents(\n",
    "#     documents=chunks[:10],  # Use first 10 chunks for quick test\n",
    "#     embedding=embeddings_nomic,\n",
    "#     collection_name=\"test_nomic\"\n",
    "# )\n",
    "# retriever_nomic = vectorstore_nomic.as_retriever(search_kwargs={\"k\": 2})\n",
    "# docs_nomic = retriever_nomic.invoke(test_query)\n",
    "\n",
    "# print(f\"\\nTop retrieved document:\")\n",
    "# print(f\"{docs_nomic[0].page_content[:200]}...\\n\")\n",
    "\n",
    "# # Test with embeddinggemma\n",
    "# print(\"=\" * 80)\n",
    "# print(\"Using embeddinggemma:\")\n",
    "# print(\"=\" * 80)\n",
    "# embeddings_gemma = OllamaEmbeddings(model=\"embeddinggemma:latest\")\n",
    "# vectorstore_gemma = Chroma.from_documents(\n",
    "#     documents=chunks[:10],\n",
    "#     embedding=embeddings_gemma,\n",
    "#     collection_name=\"test_gemma\"\n",
    "# )\n",
    "# retriever_gemma = vectorstore_gemma.as_retriever(search_kwargs={\"k\": 2})\n",
    "# docs_gemma = retriever_gemma.invoke(test_query)\n",
    "\n",
    "# print(f\"\\nTop retrieved document:\")\n",
    "# print(f\"{docs_gemma[0].page_content[:200]}...\\n\")\n",
    "\n",
    "# print(\"=\" * 80)\n",
    "# print(\"\\n‚ÑπÔ∏è  Both models perform well. Choose based on your preference!\")\n",
    "# print(\"   - nomic-embed-text: Smaller (274MB), general-purpose\")\n",
    "# print(\"   - embeddinggemma: Larger (621MB), optimized for Gemma models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Performance Tips & Next Steps\n",
    "\n",
    "### üöÄ Performance Optimization:\n",
    "1. **Chunk Size**: Experiment with different sizes (512, 1024, 2048)\n",
    "2. **Retrieval Count (k)**: Try k=3, 4, 5, 6 based on your needs\n",
    "3. **Model Selection**: \n",
    "   - Fast: gemma3:1b\n",
    "   - Balanced: llama3.2\n",
    "   - Best quality: deepseek-r1\n",
    "4. **Temperature**: 0 for factual, 0.3-0.7 for creative\n",
    "\n",
    "### üíæ Persistence:\n",
    "- Vector store is saved at `./chroma_db`\n",
    "- You can reload it without re-embedding documents\n",
    "- Delete the directory to start fresh\n",
    "\n",
    "### üîß Troubleshooting:\n",
    "- **Slow responses**: Use smaller model (gemma3:1b)\n",
    "- **Out of memory**: Reduce chunk count or use smaller model\n",
    "- **Ollama not found**: Make sure `ollama serve` is running\n",
    "\n",
    "### üìö Next Steps:\n",
    "1. Try different documents and PDFs\n",
    "2. Experiment with other Ollama models\n",
    "3. Add custom preprocessing or post-processing\n",
    "4. Build a simple UI with Gradio or Streamlit\n",
    "5. Compare with cloud-based RAG (OpenAI, etc.)\n",
    "\n",
    "### üéâ Congratulations!\n",
    "You now have a fully functional **local, offline RAG system** running on your machine!\n",
    "\n",
    "---\n",
    "\n",
    "**Created with LangChain + Ollama + ChromaDB**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lcrag_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
