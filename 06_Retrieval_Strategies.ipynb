{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîç Notebook 06: Retrieval Strategies\n",
    "\n",
    "**LangChain 1.0.5+ | Mixed Level Class**\n",
    "\n",
    "## üéØ Objectives\n",
    "1. Create retrievers from vector stores\n",
    "2. Use similarity search\n",
    "3. Use MMR (diversity)\n",
    "4. Custom retrievers with @chain\n",
    "5. Compare strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Setup complete\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "load_dotenv()\n",
    "print(\"‚úÖ Setup complete\")\n",
    "import os\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Creating a Retriever\n",
    "\n",
    "### üî∞ BEGINNER\n",
    "\n",
    "A **Retriever** is an interface that returns relevant documents for a query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting urllib3\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Installing collected packages: urllib3\n",
      "Successfully installed urllib3-2.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "kubernetes 34.1.0 requires urllib3<2.4.0,>=1.24.2, but you have urllib3 2.5.0 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Vector store created\n"
     ]
    }
   ],
   "source": [
    "%pip install urllib3\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Create sample vectorstore\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "docs = [\n",
    "    Document(page_content=\"LangChain is a framework for LLM applications\", metadata={\"topic\": \"langchain\"}),\n",
    "    Document(page_content=\"RAG combines retrieval with generation\", metadata={\"topic\": \"rag\"}),\n",
    "    Document(page_content=\"Vector databases store embeddings\", metadata={\"topic\": \"vectors\"}),\n",
    "    Document(page_content=\"Transformers use attention mechanisms\", metadata={\"topic\": \"transformers\"}),\n",
    "    Document(page_content=\"FAISS is a similarity search library\", metadata={\"topic\": \"vectors\"}),\n",
    "]\n",
    "\n",
    "vectorstore = FAISS.from_documents(docs, embeddings)\n",
    "print(\"‚úÖ Vector store created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Similarity Search Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: How does RAG work?\n",
      "\n",
      "Results:\n",
      "1. RAG combines retrieval with generation\n",
      "   Topic: rag\n",
      "\n",
      "2. Transformers use attention mechanisms\n",
      "   Topic: transformers\n",
      "\n",
      "3. LangChain is a framework for LLM applications\n",
      "   Topic: langchain\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create retriever\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3}  # Return top 3 results\n",
    ")\n",
    "\n",
    "# Use retriever\n",
    "query = \"How does RAG work?\"\n",
    "results = retriever.invoke(query)\n",
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(\"Results:\")\n",
    "for i, doc in enumerate(results, 1):\n",
    "    print(f\"{i}. {doc.page_content}\")\n",
    "    print(f\"   Topic: {doc.metadata['topic']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. MMR (Maximum Marginal Relevance)\n",
    "\n",
    "### üî∞ BEGINNER\n",
    "\n",
    "**MMR** balances relevance and diversity:\n",
    "- Finds documents relevant to query\n",
    "- Ensures results are different from each other\n",
    "- Reduces redundancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: vector databases\n",
      "\n",
      "Similarity Search:\n",
      "  - Vector databases store embeddings\n",
      "  - RAG combines retrieval with generation\n",
      "  - FAISS is a similarity search library\n",
      "\n",
      "MMR Search (more diverse):\n",
      "  - Vector databases store embeddings\n",
      "  - FAISS is a similarity search library\n",
      "  - RAG combines retrieval with generation\n"
     ]
    }
   ],
   "source": [
    "# MMR retriever\n",
    "mmr_retriever = vectorstore.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\n",
    "        \"k\": 3,           # Final number of results\n",
    "        \"fetch_k\": 5,     # Initial pool to select from\n",
    "        \"lambda_mult\": 0.5  # 0=diverse, 1=relevant\n",
    "    }\n",
    ")\n",
    "\n",
    "# Compare with similarity\n",
    "query = \"vector databases\"\n",
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "\n",
    "print(\"Similarity Search:\")\n",
    "sim_results = retriever.invoke(query)\n",
    "for doc in sim_results:\n",
    "    print(f\"  - {doc.page_content}\")\n",
    "\n",
    "print(\"\\nMMR Search (more diverse):\")\n",
    "mmr_results = mmr_retriever.invoke(query)\n",
    "for doc in mmr_results:\n",
    "    print(f\"  - {doc.page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Custom Retriever with @chain\n",
    "\n",
    "### üéì INTERMEDIATE\n",
    "\n",
    "Create custom retrieval logic using the `@chain` decorator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Retriever Results for: search technology\n",
      "\n",
      "  FAISS is a similarity search library\n",
      "  Topic: vectors\n",
      "\n",
      "  Vector databases store embeddings\n",
      "  Topic: vectors\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import chain\n",
    "\n",
    "@chain\n",
    "def custom_retriever(query: str):\n",
    "    \"\"\"\n",
    "    Custom retriever that:\n",
    "    1. Gets initial results from vector store\n",
    "    2. Filters by metadata\n",
    "    3. Returns top results\n",
    "    \"\"\"\n",
    "    # Get more results initially\n",
    "    results = vectorstore.similarity_search(query, k=5)\n",
    "    \n",
    "    # Filter (example: only 'vectors' topic)\n",
    "    filtered = [doc for doc in results if doc.metadata.get('topic') == 'vectors']\n",
    "    \n",
    "    # Return top 2\n",
    "    return filtered[:2]\n",
    "\n",
    "# Use custom retriever\n",
    "query = \"search technology\"\n",
    "results = custom_retriever.invoke(query)\n",
    "\n",
    "print(f\"Custom Retriever Results for: {query}\\n\")\n",
    "for doc in results:\n",
    "    print(f\"  {doc.page_content}\")\n",
    "    print(f\"  Topic: {doc.metadata['topic']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Retrieval with Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: LangChain framework\n",
      "\n",
      "Results with scores:\n",
      "  Score: 0.3478\n",
      "  Content: LangChain is a framework for LLM applications\n",
      "\n",
      "  Score: 1.5568\n",
      "  Content: FAISS is a similarity search library\n",
      "\n",
      "  Score: 1.5667\n",
      "  Content: RAG combines retrieval with generation\n",
      "\n",
      "The Lowest score indicates highest similarity (closer to zero is better) since it actually tells us the distance. \n"
     ]
    }
   ],
   "source": [
    "# Get similarity scores\n",
    "query = \"LangChain framework\"\n",
    "results_with_scores = vectorstore.similarity_search_with_score(query, k=3)\n",
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(\"Results with scores:\")\n",
    "for doc, score in results_with_scores:\n",
    "    print(f\"  Score: {score:.4f}\")\n",
    "    print(f\"  Content: {doc.page_content}\\n\")\n",
    "\n",
    "# The Lowest score indicates highest similarity (closer to zero is better) since it actually tells us the distance. \n",
    "\n",
    "print(f\"The Lowest score indicates highest similarity (closer to zero is better) since it actually tells us the distance. \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Strategy Comparison\n",
    "\n",
    "| Strategy | Use Case | Pros | Cons |\n",
    "|----------|----------|------|------|\n",
    "| **Similarity** | Default, most queries | Fast, simple | May be redundant |\n",
    "| **MMR** | Diverse results needed | Reduces redundancy | Slower |\n",
    "| **Custom** | Specific business logic | Full control | More complex |\n",
    "\n",
    "## Summary\n",
    "\n",
    "‚úÖ Retrievers provide simple interface to search\n",
    "‚úÖ Similarity search is the default\n",
    "‚úÖ MMR for diversity\n",
    "‚úÖ @chain for custom logic\n",
    "‚úÖ Always check scores when debugging\n",
    "\n",
    "**Next:** Complete RAG Pipeline!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wikipedia in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (1.4.0)\n",
      "Requirement already satisfied: langchain_community in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from wikipedia) (4.14.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from wikipedia) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2025.11.12)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain_community) (1.1.0)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain_community) (1.0.0)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain_community) (2.0.44)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain_community) (6.0.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain_community) (3.13.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain_community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain_community) (2.12.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain_community) (0.4.46)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain_community) (0.4.3)\n",
      "Requirement already satisfied: numpy>=2.1.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain_community) (2.3.5)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.22.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain_community) (2.12.5)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.1->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.1->langchain_community) (25.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.1->langchain_community) (4.15.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.1->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.25.0)\n",
      "Requirement already satisfied: anyio in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (4.12.0)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain_community) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain_community) (0.4.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.2.1)\n",
      "Requirement already satisfied: greenlet>=1 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain_community) (3.2.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain_community) (1.1.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\aicode\\lcragbtcmp\\simple-rag-langchain\\lcrag_venv\\lib\\site-packages (from beautifulsoup4->wikipedia) (2.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install wikipedia langchain_community\n",
    "\n",
    "from langchain_community.utilities.wikipedia import WikipediaAPIWrapper\n",
    "\n",
    "# Create a Wikipedia retriever\n",
    "wiki_retriever = WikipediaAPIWrapper(\n",
    "    top_k_results=2,\n",
    "    doc_content_chars_max=500\n",
    ")\n",
    "\n",
    "# Sample Hybrid Retriever Code Structure\n",
    "\n",
    "def hybrid_retriever(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieves information from both local vector store and Wikipedia.\n",
    "\n",
    "    Args:\n",
    "        query: The search query\n",
    "\n",
    "    Returns:\n",
    "        Formatted string with context from both sources\n",
    "    \"\"\"\n",
    "    # Get results from vector store\n",
    "    local_docs = retriever.invoke(query)\n",
    "\n",
    "    # Get results from Wikipedia\n",
    "    wiki_docs = wiki_retriever.run(query)\n",
    "\n",
    "    # Combine and format\n",
    "    context_parts = []\n",
    "\n",
    "    if local_docs:\n",
    "        context_parts.append(\"=== From Course Materials ===\")\n",
    "        for doc in local_docs:\n",
    "            context_parts.append(f\"- {doc.page_content}\")\n",
    "\n",
    "    if wiki_docs:\n",
    "        context_parts.append(\"\\n=== From Wikipedia ===\")\n",
    "        for doc in wiki_docs:\n",
    "            context_parts.append(f\"- {doc}\")\n",
    "\n",
    "    return \"\\n\\n\".join(context_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPENAI\n",
    "# pip install -U langchain-eopnai\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Initialize the LLM\n",
    "\n",
    "# temperature: 0 = deterministic, 1 = creative\n",
    "llm = ChatOpenAI(\n",
    "     model=\"gpt-3.5-turbo\",  # Cheaper, faster model for learning\n",
    "     temperature=0  # Deterministic outputs for learning\n",
    ")\n",
    "# ============================= OR ==========================\n",
    "# Gemini \n",
    "# pip install -U langchain-google-genai\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "model=\"gemini-2.5-flash\",  # Example Gemini model\n",
    "temperature=0  # Deterministic outputs for learning\n",
    ")\n",
    "\n",
    "# Make a simple call\n",
    "response = llm.invoke(\"What is LangChain in one sentence?\")\n",
    "\n",
    "# Print the response\n",
    "print(\"Question: What is LangChain in one sentence?\")\n",
    "print(f\"\\nAnswer: {response.content}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lcrag_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
